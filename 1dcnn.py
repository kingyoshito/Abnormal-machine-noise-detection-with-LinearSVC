# -*- coding: utf-8 -*-
"""1DCNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YXpd6Y3_gcIvBHQmSyaiLd1MPoqwkHTc
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import glob
from sklearn.model_selection import train_test_split
from keras.optimizers import RMSprop
from tensorflow.keras.layers import Dense, Dropout, Flatten,Conv2D, MaxPooling2D
from tensorflow.keras import Sequential
from sklearn.metrics import classification_report
from matplotlib import pyplot as plt
import keras
from keras.layers.convolutional import Conv1D, UpSampling1D
from keras.layers.pooling import MaxPooling1D
from tensorflow.keras.layers import BatchNormalization

image_path = "/content/drive/MyDrive/00_all_train/normal/*"
image_path2 = "/content/drive/MyDrive/00_all_train/anomaly/*"

files = glob.glob(image_path)
files2 = glob.glob(image_path2)
print('nomal',*files,sep='\n')
print()
print('anomaly',*files2,sep='\n')

nomal = []
anomaly = []

for i,f in enumerate (files):
    df = pd.read_csv(f, header = None)
    im = np.array(df)
    nomal.append(im)

for n,t in enumerate(files2):
    df2 = pd.read_csv(f, header = None)
    im2 = np.array(df2)
    anomaly.append(im2)
    
nomal.extend(anomaly)
x_train = np.array(nomal)
x_train.shape#データ数は200個で32769*7

nomal = [0]*100
anomaly = [1]*100

nomal.extend(anomaly)
y_train = np.array(nomal)
y_train = y_train.astype("uint8")

x_train1, x_valid, y_train1, y_valid = train_test_split(x_train, y_train, test_size=0.3, random_state=6)

#モデル
model = Sequential()

model.add(Conv1D(filters=128,kernel_size=2,activation='relu',input_shape=(32769,7)))
model.add(BatchNormalization())
model.add(Dropout(0.2))
model.add(Conv1D(filters=128,kernel_size=7,activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(Flatten())
model.add(Dense(128,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(2,activation='sigmoid'))

model.summary()

x_train = x_train.astype('float32')
x_valid = x_valid.astype('float32')


y_valid2 = y_valid
y_train = keras.utils.to_categorical(y_train, 2)
y_valid = keras.utils.to_categorical(y_valid, 2)

#学習
model.compile(loss='binary_crossentropy',
              optimizer="adam",
              metrics=['accuracy'])


history = model.fit(x_train, y_train,
                    batch_size=2,
                    epochs=20,
                    verbose=1,
                    validation_data=(x_valid, y_valid))

plt.plot(history.history["accuracy"])
plt.plot(history.history["val_accuracy"])

plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend(['train'])
plt.show()

y_pred = model.predict(x_valid)
signal_rate  = np.array(y_pred)
print("Probability of being nomal","/","Probability of being anomaly")
print(np.round(signal_rate[0:len(signal_rate)],2))

y_pred = np.argmax(y_pred,axis = 1)
y_pred

print(classification_report(y_valid2,y_pred))

from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_valid2,y_pred))
print("正常であるが、異常と検知した識別",np.where((y_pred != y_valid2) & (y_valid2 == 0)))
print("異常だが、正常と識別",np.where((y_pred != y_valid2) & (y_valid2 == 1)))

plt.imshow(x_valid[47])
print("異常である確率","/","正常である確率")
print(signal_rate[47])

aaaa
